# TheDataAlchemist ğŸ§™â€â™‚ï¸

[![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PyQt5](https://img.shields.io/badge/PyQt5-5.15+-green.svg)](https://www.riverbankcomputing.com/software/pyqt/)
[![CrewAI](https://img.shields.io/badge/CrewAI-0.51+-red.svg)](https://github.com/joaomdmoura/crewai)
[![Plotly](https://img.shields.io/badge/Plotly-5.17+-orange.svg)](https://plotly.com/)

**TheDataAlchemist** is an intelligent, AI-powered desktop application that transforms raw CSV datasets into comprehensive, publication-ready analytical reports. Leveraging advanced multi-agent AI systems, it automates the entire data analysis pipeline from ingestion to insight generation.

## ğŸ“‹ Table of Contents

- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Configuration](#configuration)
- [Architecture](#architecture)
- [Project Structure](#project-structure)
- [Demo Materials](#demo-materials)
- [Performance](#performance)
- [Security](#security)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)
- [License](#license)

## ğŸš€ Features

### ğŸ¤– Multi-Agent AI Architecture
- **Reading Agent**: Intelligently analyzes CSV structure and data characteristics
- **Code Generation Agents**: Creates Plotly visualizations at multiple complexity levels:
  - Simple Analysis (basic charts and distributions)
  - Intermediate Analysis (correlations and trends)
  - Advanced Analysis (complex statistical visualizations)
- **Insights Agent**: Transforms visualizations into compelling narrative stories

### ğŸ“Š Automated Analysis Pipeline
- **Intelligent Data Profiling**: Automatically detects column types, distributions, and relationships
- **Dynamic Visualization Generation**: Creates contextually appropriate charts and graphs
- **Narrative Insight Generation**: Converts technical visualizations into business-friendly stories
- **Multi-format Export**: Generates professional HTML reports with interactive visualizations

### ğŸ¨ Professional Report Generation
- **Light & Dark Themes**: Choose between elegant light and modern dark report themes
- **Responsive Design**: Reports adapt to different screen sizes
- **Interactive Visualizations**: Embedded Plotly charts for data exploration
- **Structured Layout**: Clean, publication-ready formatting

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8 or higher
- Valid Google Gemini API key (for AI analysis)
- Git (for cloning repository)

### Setup Instructions

1. **Clone the repository**
   ```bash
   git clone https://github.com/DeepActionPotential/TheDataAlchemist
   cd TheDataAlchemist
   ```

2. **Create virtual environment (recommended)**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure API Keys**
   Edit `config.py` and replace placeholder API keys:
   ```python
   api_key: str = "your-actual-gemini-api-key-here"
   ```



## ğŸ“– Usage

### Basic Workflow

1. **Launch Application**: Run `python app.py` to start the GUI
2. **Select Dataset**: Choose any CSV file for analysis via the file dialog
3. **Configure Analysis**:
   - Set number of analyses (default: 50)
   - Choose report title and styling preferences
   - Select light or dark theme
4. **Generate Report**: Click "Analyze & Generate Report"
5. **View Results**: Open the generated HTML report in your browser

### Advanced Configuration

#### Analysis Parameters
```python
# In app.py - adjust analysis parameters
number_of_analyses: int = 50  # More = deeper analysis, longer processing
dark_theme: bool = False      # Toggle dark/light theme
report_title: str = "Custom Report Title"
```

#### API Configuration
The application uses Google Gemini 2.0 Flash by default. Quality and rate limits depend on your API plan:

- **Free Tier**: Limited requests per minute, basic analysis capabilities
- **Paid Tier**: Higher rate limits, more sophisticated insights, better narrative generation

> **Important**: Report quality and analysis depth heavily depend on your Gemini API tier. Free tier may produce basic insights, while paid tiers enable more sophisticated analysis and better narrative generation.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PyQt5 GUI     â”‚â”€â”€â”€â–¶â”‚  DatasetAnalyzer â”‚â”€â”€â”€â–¶â”‚   Report        â”‚
â”‚   Interface     â”‚    â”‚  (Orchestrator)  â”‚    â”‚   Generator     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  File Selection â”‚    â”‚  CrewAI Agents   â”‚    â”‚  HTML Templates â”‚
â”‚  & Configurationâ”‚    â”‚  - Reading       â”‚    â”‚  - Light Theme  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  - Code Gen      â”‚    â”‚  - Dark Theme   â”‚
                       â”‚  - Insights      â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack
- **Frontend**: PyQt5 (Desktop GUI)
- **AI Framework**: CrewAI (Multi-agent system)
- **LLM Provider**: Google Gemini 2.0 Flash
- **Visualization**: Plotly (Interactive charts)
- **Data Processing**: Pandas (Data manipulation)
- **Report Generation**: HTML/CSS with embedded Plotly

## ğŸ“ Project Structure

```
TheDataAlchemist/
â”œâ”€â”€ ğŸ“„ app.py                 # Main application entry point
â”œâ”€â”€ âš™ï¸ config.py              # API keys and configuration
â”œâ”€â”€ ğŸ“¦ requirements.txt       # Python dependencies
â”œâ”€â”€ ğŸ§  agents/                # AI agent implementations
â”‚   â”œâ”€â”€ reading_agents.py     # Data reading and profiling
â”‚   â”œâ”€â”€ code_agents.py        # Visualization code generation
â”‚   â””â”€â”€ insights_agents.py    # Narrative insight creation
â”œâ”€â”€ ğŸ”§ core/                  # Core business logic
â”‚   â””â”€â”€ dataset_manager.py    # Main analysis orchestrator
â”œâ”€â”€ ğŸ”— services/              # Business services
â”‚   â”œâ”€â”€ csv_analyses.py       # Dataset analysis coordination
â”‚   â””â”€â”€ report_manager.py     # Report generation
â”œâ”€â”€ ğŸ–¥ï¸ ui/                    # User interface
â”‚   â””â”€â”€ main_ui.py            # PyQt5 GUI implementation
â”œâ”€â”€ ğŸ› ï¸ utils/                 # Utility functions
â”‚   â””â”€â”€ utils.py              # Helper functions
â”œâ”€â”€ ğŸ“„ templates/             # HTML report templates
â”‚   â”œâ”€â”€ report_light_theme.html
â”‚   â”œâ”€â”€ report_dark_theme.html
â”‚   â””â”€â”€ page_block.html
â”œâ”€â”€ ğŸ¬ demo/                  # Demo materials
â”‚   â”œâ”€â”€ demo.mp4             # Video demonstration (6.6MB)
â”‚   â”œâ”€â”€ demo1.png           # Screenshot 1: Main interface (1.1MB)
â”‚   â”œâ”€â”€ demo2.png           # Screenshot 2: Analysis in progress (100KB)
â”‚   â”œâ”€â”€ demo3.png           # Screenshot 3: Report preview (60KB)
â”‚   â”œâ”€â”€ demo4.png           # Screenshot 4: Sample visualization (59KB)
â”‚   â””â”€â”€ demo5.png           # Screenshot 5: Final report (89KB)
â””â”€â”€ ğŸ“Š data.csv              # Sample dataset for testing
```

## ğŸ¬ Demo Materials

The `demo/` folder contains comprehensive demonstration materials:

### ğŸ“¹ Video Demonstration
### Videos
- <video src="./demo/demo.mp4" controls width="720"> </video>


### Images
- `demo1.png` - ![Demo 1](./demo/demo1.png)
- `demo2.png` - ![Demo 2](./demo/demo2.png)
- `demo3.png` - ![Demo 3](./demo/demo3.png)
- `demo4.png` - ![Demo 4](./demo/demo4.png)


## âš¡ Performance

### Analysis Speed Factors
- **Dataset Size**: Larger files take longer to process (typical: 10-300 seconds)
- **Number of Analyses**: More analyses = longer processing time (50 analyses â‰ˆ 2-5 minutes)
- **API Rate Limits**: Free tier vs paid tier affects speed significantly
- **Hardware**: SSD storage recommended for faster I/O operations

### Memory Usage
- **Base Application**: ~50-100MB RAM
- **Large Datasets**: May require 500MB-2GB RAM during processing
- **Report Generation**: HTML rendering can be memory-intensive for large reports

### Optimization Tips
- Use SSD storage for faster file operations
- Close other applications during large dataset processing
- Consider upgrading to Gemini paid tier for faster analysis

## ğŸ”’ Security & Privacy

### Data Protection
- **Local Processing**: All analysis happens on your local machine
- **No Data Upload**: Raw datasets never leave your computer
- **API Security**: Only API keys are transmitted to Google's servers
- **Temporary Files**: Generated reports are temporary unless explicitly saved

### Best Practices
- Store API keys securely (not in plain text)
- Use virtual environments for dependency isolation
- Regularly update dependencies for security patches
- Validate input CSV files for malicious content

## ğŸš¨ Troubleshooting

### Common Issues and Solutions

**"onnxruntime DLL load failed"**
```bash
pip uninstall onnxruntime
pip install onnxruntime==1.16.3
```

**"chromadb import error"**
- Ensure all requirements are installed in correct order
- Check Python version compatibility (3.8-3.11)
- Clear pip cache: `pip cache purge`

**"API rate limit exceeded"**
- Upgrade to Gemini paid tier for higher limits
- Increase `time_to_sleep_between_requests` in config.py
- Reduce `number_of_analyses` parameter

**"PyQt5 display issues"**
- Ensure display/graphics drivers are updated
- Try running in virtual environment
- Check system compatibility (Windows 10+ recommended)

**"Memory errors with large datasets"**
- Increase system RAM or close other applications
- Process datasets in smaller chunks
- Use sampling for exploratory analysis

## ğŸ¤ Contributing

We welcome contributions! Here's how to get involved:

### Development Setup
1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes following the existing code style
4. Add tests for new functionality
5. Ensure all tests pass: `python -m pytest`
6. Commit your changes: `git commit -m 'Add amazing feature'`
7. Push to the branch: `git push origin feature/amazing-feature`
8. Open a Pull Request

### Contribution Guidelines
- Follow PEP 8 style guidelines
- Add docstrings for new functions/classes
- Update README for significant changes
- Test changes thoroughly before submitting

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **CrewAI Team** - For the excellent multi-agent framework
- **Google AI** - For the Gemini API powering our analysis
- **Plotly Team** - For beautiful, interactive visualizations
- **Riverbank Computing** - For the PyQt5 framework
- **Pandas Community** - For essential data manipulation tools

## ğŸ“ Support

For support and questions:

- ğŸ“§ **Email**: support@thedataalchemist.com
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/yourusername/TheDataAlchemist/discussions)
- ğŸ› **Issues**: [GitHub Issues](https://github.com/yourusername/TheDataAlchemist/issues)
- ğŸ“– **Documentation**: [Wiki](https://github.com/yourusername/TheDataAlchemist/wiki)

### Getting Help
1. Check the troubleshooting section above
2. Review demo materials in the `demo/` folder
3. Examine the sample `Titanic data report.html` for reference
4. Search existing GitHub issues for similar problems

